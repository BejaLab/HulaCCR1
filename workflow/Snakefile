
from pandas import read_excel
import warnings

# all datasets as { dataset: basename } dict
datasets = dict(zip(*glob_wildcards("datasets/{dataset}/{basename}.fna")))

# dataset metadata
with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    metadata = read_excel("metadata/datasets.xlsx").set_index('analysis').T.to_dict('dict')

# dict of metatranscriptomic datasets
metat_datasets = { ds: datasets[ds] for ds in datasets.keys() if metadata[ds]['type'] == 'Metatranscriptome' }

# reference PDB accession of HcKCR1 for alignment trimming
pdb_ref = "8H86"

rule all:
    input:
        "output/clade_dist.csv"

rule dload_pdb:
    output:
        "analysis/pdb/{acc}.pdb"
    shell:
        "wget -O {output} https://files.rcsb.org/download/{wildcards.acc}.pdb"

rule dssp:
    input:
        "analysis/pdb/{acc}.pdb"
    output:
        "analysis/pdb/{acc}.dssp"
    conda:
        "envs/dssp.yaml"
    shell:
        "mkdssp {input} > {output}"

rule align_refs:
    input:
        "metadata/BCCRs.faa"
    output:
        "analysis/proteins/BCCRs.mafft"
    conda:
        "envs/mafft.yaml"
    threads:
        20
    shell:
        "mafft --thread {threads} --reorder --auto {input} > {output}"

rule trim_tms:
    input:
        dssp = "analysis/pdb/{acc}.dssp".format(acc = pdb_ref),
        aln = "analysis/proteins/BCCRs.mafft"
    output:
        "analysis/proteins/BCCRs_TM.faa"
    conda:
        "envs/biopython.yaml"
    script:
        "scripts/trim_tms.py"

rule makeblastdb_prot:
    input:
        "{prefix}.faa"
    output:
        "{prefix}.faa.pdb"
    conda:
        "envs/blast.yaml"
    shell:
        "makeblastdb -in {input} -dbtype prot"

rule blastx:
    input:
        query = "datasets/{dataset}/{basename}.fna",
        db = "analysis/proteins/BCCRs_TM.faa",
        pdb = "analysis/proteins/BCCRs_TM.faa.pdb"
    output:
        "analysis/blastx/{dataset}/{basename}.txt"
    params:
        evalue = 1e-5
    conda:
        "envs/blast.yaml"
    threads:
        8
    shell:
        "blastx -query {input.query} -db {input.db} -outfmt 6 -out {output} -evalue {params.evalue} -num_threads {threads} -ungapped -comp_based_stats F"

rule blastx_filter:
    input:
        "analysis/blastx/{dataset}/{basename}.txt"
    output:
        "analysis/blastx/{dataset}/{basename}_filtered.tsv"
    params:
        min_len = 25,
        min_ident = 70,
        regex = "mgCCR1"
    conda:
        "envs/kits.yaml"
    shell:
        "awk '!_[$1] && $2 ~ /{params.regex}/ && $3>={params.min_ident} && $4>={params.min_len}; {{_[$1]=1}}' {input} > {output}"

rule clade_dist:
    input:
        expand("analysis/blastx/{dataset}/{basename}_filtered.tsv", zip, dataset = datasets.keys(), basename = datasets.values())
    output:
        "output/clade_dist.csv"
    params:
        datasets = datasets
    conda:
        "envs/r.yaml"
    script:
        "scripts/clade_dist.R"

rule hmmsearch:
    input:
        fasta = "datasets/{dataset}/{basename}.fna",
        hmm = "profiles/{profile}.hmm"
    output:
        txt = "analysis/hmmsearch/{profile}/{dataset}/{basename}.txt",
        tblout = "analysis/hmmsearch/{profile}/{dataset}/{basename}.tblout"
    params:
        minsize = 300 # min ORF size
    conda:
        "envs/hmmer.yaml"
    shell:
        "getorf -minsize {params.minsize} -filter -find 0 {input.fasta} | hmmsearch --cut_tc -o {output.txt} --tblout {output.tblout} {input.hmm} -"

rule hmmsearch_extract:
    input:
        fasta = "datasets/{dataset}/{basename}.fna",
        tblout = "analysis/hmmsearch/{profile}/{dataset}/{basename}.tblout"
    output:
        "analysis/hmmsearch/{profile}/{dataset}/{basename}.fna"
    conda:
        "envs/kits.yaml"
    shell:
        "cut -f1 -d' ' {input.tblout} | grep -v '^#' | sed -E 's/_[0-9]+$//' | seqkit grep -f- -o {output} {input.fasta}"
